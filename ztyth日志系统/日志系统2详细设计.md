
## logstash 安装
安装略
#安装时注意有没有问题，如有问题需要特殊处理下

## logstash 配置

添加hosts
vim /etc/hosts
`
192.168.112.191 hadoop1 bd-hadoop1
192.168.112.192 hadoop2 bd-hadoop2
192.168.112.193 hadoop3 bd-hadoop3
`


vim /etc/logstash/conf.d/logHDFS.conf
`
input {
	kafka {
		bootstrap_servers => ["192.168.12.6:19092,192.168.12.6:19093"]
		topics => "logHDFS"
        group_id=> "default"
		codec => "json"
	}
}

filter {
	mutate {
		add_field => {"logpath" => "%{[fields][system_id]}"}
	}
}

output {
	stdout {}
    webhdfs {
        host => "192.168.112.192"
        port => 50070
        path => "/data/logHDFS/%{logpath}/%{+yyyy-MM-dd}.log"
        user => "hdfs"
    }
}

`


## filebeat安装 win
linux略
1. Download the Filebeat Windows zip file from the downloads page.
2. Extract the contents of the zip file into C:\Program Files.
3. Rename the filebeat-<version>-windows directory to Filebeat.
4. Open a PowerShell prompt as an Administrator (right-click the PowerShell icon and select Run As Administrator).
From the PowerShell prompt, run the following commands to install Filebeat as a Windows service:
PS > cd 'C:\Program Files\Filebeat'
PS C:\Program Files\Filebeat> .\install-service-filebeat.ps1

## filebeats 配置
修改或者新增filebeat.yml
`
filebeat.prospectors:
- input_type: log
  paths:
   - F:/temp/log/*
  encoding:GB2312
  fields:
    system_id: apollo
  multiline:
    pattern: '^发生时间'
    negate: true
    match: after
output.kafka:
  hosts: ["192.168.12.6:19092", "192.168.12.6:19093"]
  topic: 'logHDFS'
  key: 'apollo'
  partition.hash:
    hash: []
    reachable_only: true

  required_acks: 1
  compression: gzip
  max_message_bytes: 10000000

`

## 启动
filebeats 通过服务管理 或者  sc start filebeat
logstash ： systemctl restart logstash

## 查看日志
filebeat：C:\ProgramData\filebeat
logstash： vim /var/log/logstash/logstash-plain.log